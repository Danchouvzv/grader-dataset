#!/usr/bin/env python3
"""
Baseline –º–æ–¥–µ–ª—å –¥–ª—è sanity-check –¥–∞—Ç–∞—Å–µ—Ç–∞

–°—Ä–∞–≤–Ω–µ–Ω–∏–µ v1.0 vs v1.1 preview:
- TF-IDF + RandomForest/XGBoost
- Multi-output —Ä–µ–≥—Ä–µ—Å—Å–∏—è (Overall, FC, LR, GRA, PR)
- Train/Val split –ø–æ user_id
- –ú–µ—Ç—Ä–∏–∫–∏: MAE, Spearman correlation
"""

import csv
import numpy as np
from collections import defaultdict
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.stats import spearmanr
import re

def load_answers_from_csv(filepath: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã –∏–∑ CSV"""
    answers = []
    with open(filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            try:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                overall = float(row.get('target_band_overall', 0))
                if overall < 3.0 or overall > 9.0:
                    continue
                answers.append(row)
            except:
                continue
    return answers

def extract_handcrafted_features(text: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç hand-crafted —Ñ–∏—á–∏"""
    words = text.split()
    num_words = len(words)
    
    # Filler words
    fillers = ['um', 'uh', 'er', 'erm', 'like', 'you know', 'well', 'actually', 'I mean']
    filler_count = sum(1 for word in words if any(filler in word.lower() for filler in fillers))
    
    # Connectors
    connectors = ['however', 'on the other hand', 'in addition', 'moreover', 'furthermore',
                  'although', 'despite', 'nevertheless', 'also', 'besides']
    connector_count = sum(1 for word in words if any(conn in word.lower() for conn in connectors))
    
    # Repetitions (–ø—Ä–æ—Å—Ç–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ)
    unique_words = len(set(word.lower() for word in words))
    repetition_ratio = 1 - (unique_words / num_words) if num_words > 0 else 0
    
    # Punctuation issues
    punctuation_count = text.count('.') + text.count(',') + text.count('!') + text.count('?')
    ellipsis_count = text.count('...')
    
    # Grammar indicators (–ø—Ä–æ—Å—Ç–æ–µ)
    grammar_errors = 0
    # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∞—Ä—Ç–∏–∫–ª–∏ (–æ—á–µ–Ω—å –≥—Ä—É–±–æ)
    if re.search(r'\bI like \w+$', text, re.IGNORECASE):
        grammar_errors += 1
    # Third person errors
    if re.search(r'\b(he|she|it) (go|do|make|take)\b', text, re.IGNORECASE):
        grammar_errors += 1
    
    return {
        'num_words': num_words,
        'filler_ratio': filler_count / num_words if num_words > 0 else 0,
        'connector_ratio': connector_count / num_words if num_words > 0 else 0,
        'repetition_ratio': repetition_ratio,
        'punctuation_ratio': punctuation_count / num_words if num_words > 0 else 0,
        'ellipsis_ratio': ellipsis_count / num_words if num_words > 0 else 0,
        'grammar_errors': grammar_errors,
    }

def prepare_data(answers, vectorizer=None, fit_vectorizer=True):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    texts = []
    handcrafted_features = []
    targets = {
        'overall': [],
        'fc': [],
        'lr': [],
        'gra': [],
        'pr': []
    }
    
    for answer in answers:
        text = answer.get('answer_text', '') or answer.get('transcript_raw', '')
        if not text:
            continue
        
        texts.append(text)
        handcrafted_features.append(extract_handcrafted_features(text))
        
        try:
            targets['overall'].append(float(answer['target_band_overall']))
            targets['fc'].append(float(answer['target_band_fc']))
            targets['lr'].append(float(answer['target_band_lr']))
            targets['gra'].append(float(answer['target_band_gra']))
            targets['pr'].append(float(answer['target_band_pr']))
        except:
            continue
    
    # TF-IDF
    if fit_vectorizer:
        vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 2), min_df=2)
        tfidf_features = vectorizer.fit_transform(texts)
    else:
        tfidf_features = vectorizer.transform(texts)
    
    # Hand-crafted features
    hc_array = np.array([
        [hc['num_words'], hc['filler_ratio'], hc['connector_ratio'],
         hc['repetition_ratio'], hc['punctuation_ratio'], hc['ellipsis_ratio'],
         hc['grammar_errors']]
        for hc in handcrafted_features
    ])
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ–∏—á–∏
    from scipy.sparse import hstack
    X = hstack([tfidf_features, hc_array])
    
    y = np.array([targets['overall'], targets['fc'], targets['lr'], 
                  targets['gra'], targets['pr']]).T
    
    return X, y, vectorizer

def split_by_user(answers):
    """–†–∞–∑–¥–µ–ª—è–µ—Ç –Ω–∞ train/val –ø–æ user_id"""
    users = defaultdict(list)
    for answer in answers:
        user_id = answer.get('user_id', '')
        if user_id:
            users[user_id].append(answer)
    
    user_ids = list(users.keys())
    np.random.seed(42)
    np.random.shuffle(user_ids)
    
    split_idx = int(len(user_ids) * 0.8)
    train_users = set(user_ids[:split_idx])
    val_users = set(user_ids[split_idx:])
    
    train_answers = [a for a in answers if a.get('user_id', '') in train_users]
    val_answers = [a for a in answers if a.get('user_id', '') in val_users]
    
    return train_answers, val_answers

def evaluate_model(y_true, y_pred, metric_name="MAE"):
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å"""
    results = {}
    
    criteria = ['overall', 'fc', 'lr', 'gra', 'pr']
    
    for i, criterion in enumerate(criteria):
        true_vals = y_true[:, i]
        pred_vals = y_pred[:, i]
        
        if metric_name == "MAE":
            score = mean_absolute_error(true_vals, pred_vals)
        elif metric_name == "RMSE":
            score = np.sqrt(mean_squared_error(true_vals, pred_vals))
        elif metric_name == "Spearman":
            corr, _ = spearmanr(true_vals, pred_vals)
            score = corr if not np.isnan(corr) else 0.0
        
        results[criterion] = score
    
    return results

def evaluate_by_band_range(y_true, y_pred):
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º band scores"""
    overall_true = y_true[:, 0]
    overall_pred = y_pred[:, 0]
    
    ranges = {
        'low (‚â§5.0)': (overall_true <= 5.0),
        'medium (5.5-6.5)': (overall_true >= 5.5) & (overall_true <= 6.5),
        'high (‚â•7.0)': (overall_true >= 7.0),
    }
    
    results = {}
    for range_name, mask in ranges.items():
        if np.sum(mask) > 0:
            mae = mean_absolute_error(overall_true[mask], overall_pred[mask])
            results[range_name] = {
                'mae': mae,
                'count': np.sum(mask)
            }
    
    return results

def main():
    print("=" * 70)
    print("BASELINE –ú–û–î–ï–õ–¨: –°–†–ê–í–ù–ï–ù–ò–ï V1.0 VS V1.1 PREVIEW")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º v1.0
    print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ v1.0...")
    v1_0_answers = load_answers_from_csv('dataset_versions/v1.0/answers.csv')
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(v1_0_answers)} –æ—Ç–≤–µ—Ç–æ–≤")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º mini-v1.1
    print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ mini-v1.1...")
    try:
        v1_1_preview = load_answers_from_csv('answers_mini_v1.1.csv')
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(v1_1_preview)} –æ—Ç–≤–µ—Ç–æ–≤")
    except FileNotFoundError:
        print("   ‚ö†Ô∏è  –§–∞–π–ª answers_mini_v1.1.csv –Ω–µ –Ω–∞–π–¥–µ–Ω")
        v1_1_preview = []
    
    if not v1_1_preview:
        print("\n‚ö†Ô∏è  Preview –Ω–µ –Ω–∞–π–¥–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å v1.0")
        all_answers = v1_0_answers
    else:
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        all_answers = v1_0_answers + v1_1_preview
        print(f"\nüìä –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(all_answers)}")
    
    # Split –ø–æ user_id
    print("\nüîÑ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val –ø–æ user_id...")
    train_answers, val_answers = split_by_user(all_answers)
    print(f"   Train: {len(train_answers)} –æ—Ç–≤–µ—Ç–æ–≤")
    print(f"   Val: {len(val_answers)} –æ—Ç–≤–µ—Ç–æ–≤")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    X_train, y_train, vectorizer = prepare_data(train_answers, fit_vectorizer=True)
    X_val, y_val, _ = prepare_data(val_answers, vectorizer=vectorizer, fit_vectorizer=False)
    
    print(f"   Train features shape: {X_train.shape}")
    print(f"   Val features shape: {X_val.shape}")
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\nü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (RandomForest, multi-output)...")
    model = RandomForestRegressor(
        n_estimators=100,
        max_depth=20,
        min_samples_split=5,
        random_state=42,
        n_jobs=-1
    )
    
    model.fit(X_train, y_train)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    print("\nüìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
    y_pred_train = model.predict(X_train)
    y_pred_val = model.predict(X_val)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    print("\n" + "=" * 70)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("=" * 70)
    
    print("\nüìà MAE (Mean Absolute Error):")
    print("\n   Train:")
    train_mae = evaluate_model(y_train, y_pred_train, "MAE")
    for criterion, mae in train_mae.items():
        print(f"      {criterion.upper()}: {mae:.3f}")
    
    print("\n   Validation:")
    val_mae = evaluate_model(y_val, y_pred_val, "MAE")
    for criterion, mae in val_mae.items():
        print(f"      {criterion.upper()}: {mae:.3f}")
    
    print("\nüìä Spearman Correlation:")
    val_spearman = evaluate_model(y_val, y_pred_val, "Spearman")
    for criterion, corr in val_spearman.items():
        print(f"      {criterion.upper()}: {corr:.3f}")
    
    print("\nüéØ –û—à–∏–±–∫–∏ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º (Overall):")
    val_by_range = evaluate_by_band_range(y_val, y_pred_val)
    for range_name, metrics in val_by_range.items():
        print(f"      {range_name}: MAE={metrics['mae']:.3f} (n={metrics['count']})")
    
    # Feature importance (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    if hasattr(model, 'feature_importances_'):
        print("\nüîç Top 10 –≤–∞–∂–Ω—ã—Ö —Ñ–∏—á–µ–π (hand-crafted):")
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 —Ñ–∏—á–µ–π (hand-crafted)
        hc_importance = model.feature_importances_[-7:]
        hc_names = ['num_words', 'filler_ratio', 'connector_ratio', 'repetition_ratio',
                   'punctuation_ratio', 'ellipsis_ratio', 'grammar_errors']
        importance_pairs = list(zip(hc_names, hc_importance))
        importance_pairs.sort(key=lambda x: x[1], reverse=True)
        for name, importance in importance_pairs[:10]:
            print(f"      {name}: {importance:.4f}")
    
    print("\n" + "=" * 70)
    print("‚úÖ Baseline –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ –æ—Ü–µ–Ω–µ–Ω–∞")
    print("=" * 70)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã –≤ Python —Ç–∏–ø—ã)
    def convert_to_python(obj):
        if isinstance(obj, dict):
            return {k: convert_to_python(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [convert_to_python(item) for item in obj]
        elif isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return obj
    
    results = {
        'train_mae': train_mae,
        'val_mae': val_mae,
        'val_spearman': val_spearman,
        'val_by_range': {k: {k2: convert_to_python(v2) for k2, v2 in v.items()} for k, v in val_by_range.items()},
    }
    
    results = convert_to_python(results)
    
    import json
    with open('baseline_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print("\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ baseline_results.json")

if __name__ == '__main__':
    main()

