#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —Å:
- –ë–æ–ª—å—à–µ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ (5-8 —à–∞–±–ª–æ–Ω–æ–≤ –Ω–∞ –¥–∏–∞–ø–∞–∑–æ–Ω)
- –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º—ã (topic_noun/topic_phrase)
- –î–∏—Å–∫—É—Ä—Å–∏–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
- –ü—Ä–∏–≤—è–∑–∫–∞ –æ—à–∏–±–æ–∫ –∫ —Å—É–±—Å–∫–æ—Ä–∞–º
- –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ quality_flag
"""

import csv
import random
import re
from typing import List, Tuple, Dict

# –î–∏—Å–∫—É—Ä—Å–∏–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π
DISCOURSE_MARKERS_LOW = ["um", "uh", "well", "actually", "I think", "you know"]
DISCOURSE_MARKERS_MID = ["well", "actually", "to be honest", "I guess", "I mean", "kind of", "I'd say"]
DISCOURSE_MARKERS_HIGH = ["actually", "to be honest", "I suppose", "I'd say", "frankly", "in fact"]

# –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –¥–ª—è –Ω–∏–∑–∫–æ–≥–æ GRA
GRAMMAR_ERRORS = {
    "third_person": [("he go", "he goes"), ("she like", "she likes"), ("it make", "it makes")],
    "articles": [("I like book", "I like the book"), ("I go to school", "I go to the school")],
    "tenses": [("I go yesterday", "I went yesterday"), ("I see him tomorrow", "I will see him tomorrow")],
    "word_order": [("I very like", "I like very much"), ("I don't know what to do", "I don't know what do")],
}

# –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –Ω–∏–∑–∫–æ–≥–æ LR
LEXICAL_REPETITION = {
    "good": ["good", "nice", "fine", "okay"],
    "like": ["like", "enjoy", "love"],
    "think": ["think", "believe", "feel"],
    "important": ["important", "significant", "crucial"],
}

def extract_topic_from_question(question: str) -> str:
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º—ã –∏–∑ –≤–æ–ø—Ä–æ—Å–∞"""
    question_lower = question.lower()
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤
    if "do you like" in question_lower or "do you enjoy" in question_lower:
        # "Do you like listening to music?" -> "listening to music"
        match = re.search(r'(?:like|enjoy)\s+(.+?)\?', question_lower)
        if match:
            topic = match.group(1).strip()
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞
            topic = re.sub(r'\b(do|you|to|the|a|an)\b', '', topic).strip()
            return topic if topic else "it"
    
    if "what kind of" in question_lower:
        # "What kind of music do you listen to?" -> "music"
        match = re.search(r'what kind of (\w+)', question_lower)
        if match:
            return match.group(1)
    
    if "how often" in question_lower:
        # "How often do you use social media?" -> "social media"
        match = re.search(r'how often do you (.+?)\?', question_lower)
        if match:
            topic = match.group(1).strip()
            # –£–±–∏—Ä–∞–µ–º "use" –µ—Å–ª–∏ –µ—Å—Ç—å
            topic = re.sub(r'\buse\b', '', topic).strip()
            return topic if topic else "it"
    
    if "what's your" in question_lower or "what is your" in question_lower:
        # "What's your favorite season?" -> "season"
        match = re.search(r'(?:what\'s|what is) your (.+?)\?', question_lower)
        if match:
            topic = match.group(1).strip()
            # –£–±–∏—Ä–∞–µ–º "favorite" –µ—Å–ª–∏ –µ—Å—Ç—å
            topic = re.sub(r'\bfavorite\b', '', topic).strip()
            return topic if topic else "it"
    
    if "how do you" in question_lower:
        # "How do you relax?" -> "relaxing"
        match = re.search(r'how do you (.+?)\?', question_lower)
        if match:
            verb = match.group(1).strip()
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≥–ª–∞–≥–æ–ª –≤ -ing —Ñ–æ—Ä–º—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if not verb.endswith('ing'):
                if verb.endswith('e'):
                    verb = verb[:-1] + 'ing'
                else:
                    verb = verb + 'ing'
            return verb
    
    # Fallback: –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ
    words = question.split()
    if words:
        return words[-1].rstrip('?')
    
    return "it"

def add_grammar_errors(text: str, gra: float) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç GRA"""
    if gra >= 6.5:
        return text  # –í—ã—Å–æ–∫–∏–π GRA - –º–∏–Ω–∏–º—É–º –æ—à–∏–±–æ–∫
    
    words = text.split()
    error_count = 0
    
    if gra <= 4.0:
        # –ú–Ω–æ–≥–æ –æ—à–∏–±–æ–∫
        max_errors = random.randint(2, 4)
        error_prob = 0.3
    elif gra <= 5.5:
        # –£–º–µ—Ä–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
        max_errors = random.randint(1, 2)
        error_prob = 0.15
    else:
        # –†–µ–¥–∫–∏–µ –æ—à–∏–±–∫–∏
        max_errors = 1
        error_prob = 0.05
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ —Ç—Ä–µ—Ç—å–µ–≥–æ –ª–∏—Ü–∞
    if gra <= 5.5 and random.random() < error_prob:
        for wrong, correct in GRAMMAR_ERRORS["third_person"]:
            if correct in text.lower() and error_count < max_errors:
                text = text.replace(correct, wrong, 1)
                error_count += 1
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ —Å –∞—Ä—Ç–∏–∫–ª—è–º–∏
    if gra <= 5.0 and random.random() < error_prob:
        for wrong, correct in GRAMMAR_ERRORS["articles"]:
            if correct.lower() in text.lower() and error_count < max_errors:
                text = re.sub(re.escape(correct), wrong, text, flags=re.IGNORECASE, count=1)
                error_count += 1
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ –≤—Ä–µ–º–µ–Ω
    if gra <= 5.5 and random.random() < error_prob:
        for wrong, correct in GRAMMAR_ERRORS["tenses"]:
            if correct.lower() in text.lower() and error_count < max_errors:
                text = re.sub(re.escape(correct), wrong, text, flags=re.IGNORECASE, count=1)
                error_count += 1
    
    return text

def add_lexical_limitations(text: str, lr: float) -> str:
    """–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –ª–µ–∫—Å–∏–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç LR"""
    if lr >= 7.0:
        return text  # –í—ã—Å–æ–∫–∏–π LR - —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞
    
    if lr <= 5.0:
        # –ù–∏–∑–∫–∏–π LR - –ø–æ–≤—Ç–æ—Ä –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª–æ–≤
        for simple_word, alternatives in LEXICAL_REPETITION.items():
            if simple_word in text.lower():
                # –ó–∞–º–µ–Ω—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –Ω–∞ –ø—Ä–æ—Å—Ç–æ–µ —Å–ª–æ–≤–æ
                for alt in alternatives:
                    if alt != simple_word and alt in text.lower():
                        text = re.sub(r'\b' + re.escape(alt) + r'\b', simple_word, text, flags=re.IGNORECASE)
    
    return text

def add_discourse_markers(text: str, overall: float) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–∏—Å–∫—É—Ä—Å–∏–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Ä–æ–≤–Ω—è"""
    if overall <= 4.5:
        markers = DISCOURSE_MARKERS_LOW
        prob = 0.4
    elif overall <= 6.5:
        markers = DISCOURSE_MARKERS_MID
        prob = 0.3
    else:
        markers = DISCOURSE_MARKERS_HIGH
        prob = 0.2
    
    if random.random() < prob:
        marker = random.choice(markers)
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–æ (–±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ)
        if not text[0].isupper():
            text = text[0].upper() + text[1:]
        text = f"{marker}, {text}"
    
    return text

def determine_quality_flag(overall: float) -> str:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ quality_flag"""
    if overall <= 3.5:
        return 'garbage'
    elif overall <= 4.5:
        return 'ok_low'  # –ü—Ä–æ—Å—Ç—ã–µ, –Ω–æ –Ω–µ garbage
    else:
        return 'ok'

def generate_part1_answer_improved(question: str, overall: float, fc: float, lr: float, gra: float, pr: float) -> Tuple[str, int]:
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ Part 1 —Å –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å—é –∏ –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ —Å—É–±—Å–∫–æ—Ä–∞–º"""
    topic = extract_topic_from_question(question)
    
    # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —É—Ä–æ–≤–Ω—è
    if overall <= 4.5:
        duration = random.randint(8, 18)
    elif overall <= 6.5:
        duration = random.randint(12, 22)
    else:
        duration = random.randint(18, 28)
    
    # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —à–∞–±–ª–æ–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
    if overall <= 4.0:
        templates = [
            f"I like {topic}. It is good.",
            f"Yes, I like it. It is... um... nice.",
            f"I think... {topic}... is good.",
            f"Yes, I do. I like it very much.",
            f"I like {topic} because it is good for me.",
            f"{topic} is good. I like it.",
            f"I think {topic} is nice thing.",
            f"Yes, I like {topic}. It make me happy.",
        ]
        
    elif overall <= 5.0:
        templates = [
            f"Yes, I do like {topic}. I think it is interesting and I enjoy it.",
            f"I really like {topic}. It makes me happy and I do it often.",
            f"Yes, I enjoy {topic}. It is one of my favorite things to do.",
            f"Well, I like {topic} quite a bit. I think it is fun and I do it when I have time.",
            f"Actually, I really enjoy {topic}. It is something I like to do in my free time.",
            f"I guess I like {topic}. It is interesting and I think it is good for me.",
            f"To be honest, I do like {topic}. I find it enjoyable and I do it regularly.",
        ]
        
    elif overall <= 6.0:
        templates = [
            f"Yes, I do enjoy {topic}. I find it quite relaxing and it helps me unwind after a busy day.",
            f"I really like {topic}. It's something I do regularly, especially on weekends when I have more free time.",
            f"Absolutely, I'm quite fond of {topic}. I think it's a great way to spend my leisure time and I always look forward to it.",
            f"Well, I'd say I really enjoy {topic}. I find it both interesting and relaxing, and it's become a regular part of my routine.",
            f"Actually, I'm quite passionate about {topic}. I think it's a wonderful way to relax and I try to make time for it whenever possible.",
            f"To be honest, I really like {topic}. It's something that brings me joy and helps me feel more balanced in my daily life.",
            f"I guess I'd say I enjoy {topic}. I find it quite engaging and it's definitely one of my preferred ways to spend free time.",
        ]
        
    elif overall <= 7.0:
        templates = [
            f"Yes, I absolutely enjoy {topic}. I find it both intellectually stimulating and personally rewarding. It's become an integral part of my daily routine.",
            f"I'm quite passionate about {topic}. I appreciate how it allows me to explore different perspectives and continuously learn new things.",
            f"Definitely, I'm very enthusiastic about {topic}. It's something that brings me both relaxation and a sense of accomplishment.",
            f"To be honest, I have a genuine appreciation for {topic}. It's something I've cultivated over time, and it continues to be a source of both inspiration and satisfaction.",
            f"Actually, I'm deeply engaged with {topic}. I find that it provides a unique combination of challenge and enjoyment that keeps me motivated.",
            f"I'd say I'm quite passionate about {topic}. It's become a fundamental aspect of how I approach life, offering both intellectual enrichment and personal fulfillment.",
        ]
        
    else:
        templates = [
            f"I have a genuine appreciation for {topic}. It's become a fundamental aspect of how I approach life, offering both intellectual enrichment and personal fulfillment.",
            f"Absolutely, I'm deeply engaged with {topic}. I find that it provides a unique combination of challenge and enjoyment that keeps me motivated.",
            f"Yes, I'm quite passionate about {topic}. It's something I've cultivated over time, and it continues to be a source of both inspiration and satisfaction.",
        ]
    
    # –í—ã–±–∏—Ä–∞–µ–º —à–∞–±–ª–æ–Ω
    answer = random.choice(templates)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏—Å–∫—É—Ä—Å–∏–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
    answer = add_discourse_markers(answer, overall)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç GRA
    answer = add_grammar_errors(answer, gra)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ª–µ–∫—Å–∏–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç LR
    answer = add_lexical_limitations(answer, lr)
    
    return answer, duration

def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
    print("=" * 70)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ô –ì–ï–ù–ï–†–ê–¶–ò–ò")
    print("=" * 70)
    
    test_questions = [
        "Do you like listening to music?",
        "How often do you use social media?",
        "What's your favorite season?",
        "How do you relax after work?",
    ]
    
    test_cases = [
        (4.0, 4.0, 3.5, 4.0, 4.5),  # –ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å, –Ω–∏–∑–∫–∏–π GRA
        (5.5, 5.5, 4.5, 6.0, 5.5),  # –°—Ä–µ–¥–Ω–∏–π, –Ω–∏–∑–∫–∏–π GRA
        (6.0, 6.5, 5.5, 7.0, 6.0),  # –°—Ä–µ–¥–Ω–∏–π, –Ω–∏–∑–∫–∏–π LR
        (7.0, 7.5, 8.0, 6.5, 7.0),  # –í—ã—Å–æ–∫–∏–π, –Ω–∏–∑–∫–∏–π GRA
    ]
    
    for question in test_questions:
        print(f"\nüìù –í–æ–ø—Ä–æ—Å: {question}")
        print(f"   –¢–µ–º–∞: {extract_topic_from_question(question)}")
        
        for overall, fc, lr, gra, pr in test_cases:
            answer, duration = generate_part1_answer_improved(question, overall, fc, lr, gra, pr)
            quality = determine_quality_flag(overall)
            print(f"\n   Overall={overall}, FC={fc}, LR={lr}, GRA={gra}, PR={pr}, Quality={quality}")
            print(f"   –û—Ç–≤–µ—Ç: {answer}")
            print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration} —Å–µ–∫")

if __name__ == '__main__':
    main()

