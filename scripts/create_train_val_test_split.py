#!/usr/bin/env python3
"""
–°–æ–∑–¥–∞–Ω–∏–µ train/val/test split —Å —É—á–µ—Ç–æ–º session_id –∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
- –ù–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç —É—Ç–µ—á–∫—É –ø–æ session_id
- –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ Part –∏ Band-–≥—Ä—É–ø–ø–∞–º
"""

import csv
import random
from collections import defaultdict

def get_band_group(overall: float) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥—Ä—É–ø–ø—É –±—ç–Ω–¥–∞"""
    if overall <= 5.5:
        return 'low'
    elif overall <= 6.5:
        return 'mid'
    else:
        return 'high'

def create_split(answers_file: str, train_ratio: float = 0.8, val_ratio: float = 0.1):
    """–°–æ–∑–¥–∞–µ—Ç train/val/test split"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ç–≤–µ—Ç—ã
    answers = []
    with open(answers_file, 'r', encoding='utf-8') as f:
        answers = list(csv.DictReader(f))
    
    print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(answers)} –æ—Ç–≤–µ—Ç–æ–≤")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ session_id
    by_session = defaultdict(list)
    for answer in answers:
        session_id = answer.get('session_id', '')
        by_session[session_id].append(answer)
    
    print(f"üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–µ—Å—Å–∏–π: {len(by_session)}")
    
    # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Å–µ—Å—Å–∏–∏ –ø–æ Part –∏ Band
    sessions_by_strata = defaultdict(list)
    
    for session_id, session_answers in by_session.items():
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π Part
        parts = [a.get('part', '') for a in session_answers]
        part_counts = defaultdict(int)
        for p in parts:
            part_counts[p] += 1
        dominant_part = max(part_counts.items(), key=lambda x: x[1])[0]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π Band
        overalls = []
        for a in session_answers:
            try:
                overalls.append(float(a.get('target_band_overall', 0)))
            except:
                pass
        
        if overalls:
            avg_overall = sum(overalls) / len(overalls)
            band_group = get_band_group(avg_overall)
        else:
            band_group = 'mid'
        
        strata = f"{dominant_part}_{band_group}"
        sessions_by_strata[strata].append(session_id)
    
    print(f"\nüìä –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è:")
    for strata, sessions in sessions_by_strata.items():
        print(f"   {strata}: {len(sessions)} —Å–µ—Å—Å–∏–π")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º —Å–µ—Å—Å–∏–∏ –Ω–∞ train/val/test
    random.seed(42)
    
    train_sessions = set()
    val_sessions = set()
    test_sessions = set()
    
    for strata, sessions in sessions_by_strata.items():
        random.shuffle(sessions)
        
        n = len(sessions)
        n_train = int(n * train_ratio)
        n_val = int(n * val_ratio)
        
        train_sessions.update(sessions[:n_train])
        val_sessions.update(sessions[n_train:n_train+n_val])
        test_sessions.update(sessions[n_train+n_val:])
    
    print(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–π:")
    print(f"   Train: {len(train_sessions)} —Å–µ—Å—Å–∏–π")
    print(f"   Val: {len(val_sessions)} —Å–µ—Å—Å–∏–π")
    print(f"   Test: {len(test_sessions)} —Å–µ—Å—Å–∏–π")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –æ—Ç–≤–µ—Ç—ã
    train_answers = []
    val_answers = []
    test_answers = []
    
    for answer in answers:
        session_id = answer.get('session_id', '')
        if session_id in train_sessions:
            train_answers.append(answer)
        elif session_id in val_sessions:
            val_answers.append(answer)
        elif session_id in test_sessions:
            test_answers.append(answer)
        else:
            # –ï—Å–ª–∏ —Å–µ—Å—Å–∏—è –Ω–µ –ø–æ–ø–∞–ª–∞ –Ω–∏–∫—É–¥–∞ (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å), –∏–¥–µ–º –≤ train
            train_answers.append(answer)
    
    print(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤:")
    print(f"   Train: {len(train_answers)} –æ—Ç–≤–µ—Ç–æ–≤ ({len(train_answers)/len(answers)*100:.1f}%)")
    print(f"   Val: {len(val_answers)} –æ—Ç–≤–µ—Ç–æ–≤ ({len(val_answers)/len(answers)*100:.1f}%)")
    print(f"   Test: {len(test_answers)} –æ—Ç–≤–µ—Ç–æ–≤ ({len(test_answers)/len(answers)*100:.1f}%)")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é
    print(f"\nüìä –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —á–∞—Å—Ç—è–º (Train):")
    train_parts = defaultdict(int)
    for a in train_answers:
        train_parts[a.get('part', '')] += 1
    for part in sorted(train_parts.keys()):
        print(f"   Part {part}: {train_parts[part]} ({train_parts[part]/len(train_answers)*100:.1f}%)")
    
    print(f"\nüìä –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –±—ç–Ω–¥–∞–º (Train):")
    train_bands = defaultdict(int)
    for a in train_answers:
        try:
            overall = float(a.get('target_band_overall', 0))
            band_group = get_band_group(overall)
            train_bands[band_group] += 1
        except:
            pass
    for band in ['low', 'mid', 'high']:
        count = train_bands.get(band, 0)
        print(f"   {band}: {count} ({count/len(train_answers)*100:.1f}%)")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    fieldnames = ['answer_id', 'session_id', 'user_id', 'part', 'question_id', 'question_text',
                 'answer_text', 'duration_sec', 'target_band_overall', 'target_band_fc',
                 'target_band_lr', 'target_band_gra', 'target_band_pr', 'transcript_raw',
                 'source_type', 'quality_flag', 'sample_weight', 'is_inconsistent']
    
    for split_name, split_answers in [('train', train_answers), ('val', val_answers), ('test', test_answers)]:
        output_file = f'dataset_versions/v1.3/{split_name}.csv'
        with open(output_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for answer in split_answers:
                row = {k: answer.get(k, '') for k in fieldnames}
                writer.writerow(row)
        print(f"\nüíæ {split_name.capitalize()} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = {
        'total_answers': len(answers),
        'train_count': len(train_answers),
        'val_count': len(val_answers),
        'test_count': len(test_answers),
        'train_ratio': len(train_answers) / len(answers),
        'val_ratio': len(val_answers) / len(answers),
        'test_ratio': len(test_answers) / len(answers),
        'total_sessions': len(by_session),
        'train_sessions': len(train_sessions),
        'val_sessions': len(val_sessions),
        'test_sessions': len(test_sessions),
    }
    
    import json
    with open('dataset_versions/v1.3/split_metadata.json', 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"\nüíæ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ dataset_versions/v1.3/split_metadata.json")
    print(f"\n‚úÖ Split —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")

if __name__ == '__main__':
    import sys
    answers_file = sys.argv[1] if len(sys.argv) > 1 else 'dataset_versions/v1.3/answers_fixed.csv'
    create_split(answers_file)

