#!/usr/bin/env python3
"""
–°–±–æ—Ä–∫–∞ v1.3 - Clean & Validated Dataset
- –£–¥–∞–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- –†–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —á–µ—Ä–µ–∑ —É–ª—É—á—à–µ–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã
- –î–æ–±–∞–≤–ª—è–µ—Ç low-band data
- –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç —á–∞—Å—Ç–∏
"""

import csv
import random
import os
import shutil
from collections import defaultdict
from generate_part1_v2_clean import generate_part1_answer_v2_clean
from generate_part2_v2_clean import generate_part2_answer_v2_clean
from generate_part3_expansion_v2 import generate_part3_answer_v2
from generate_synthetic_expansion import generate_realistic_subbands
from improve_generation import determine_quality_flag
from validate_and_filter import validate_part1, validate_part2, validate_part3

def load_validation_results():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    results = {}
    with open('docs/validation_results_v1.3.csv', 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            results[row['answer_id']] = row
    return results

def load_answers(filepath: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return list(csv.DictReader(f))

def generate_low_band_data(count: int, part: str) -> list:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ low-band –æ—Ç–≤–µ—Ç—ã"""
    from generate_synthetic_expansion import generate_part1_questions
    from generate_part2_expansion import generate_part2_questions
    from generate_part3_expansion import generate_part3_questions
    
    new_answers = []
    
    if part == '1':
        questions = generate_part1_questions()
    elif part == '2':
        questions = generate_part2_questions()
    else:
        questions = generate_part3_questions()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Å–µ—Å—Å–∏–∏
    with open('dataset_versions/v1.2/users.csv', 'r', encoding='utf-8') as f:
        users = list(csv.DictReader(f))
    with open('dataset_versions/v1.2/sessions.csv', 'r', encoding='utf-8') as f:
        sessions = list(csv.DictReader(f))
    
    user_ids = [u['user_id'] for u in users]
    session_ids = [s['session_id'] for s in sessions]
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º low-band –æ—Ç–≤–µ—Ç—ã (4.0-5.0)
    bands = [4.0, 4.5, 5.0]
    
    for i in range(count):
        overall = random.choice(bands)
        fc, lr, gra, pr = generate_realistic_subbands(overall)
        
        q_id, q_text = random.choice(questions)
        
        if part == '1':
            answer_text, duration = generate_part1_answer_v2_clean(q_text, overall, fc, lr, gra, pr)
        elif part == '2':
            answer_text, duration = generate_part2_answer_v2_clean(q_text, overall, fc, lr, gra, pr)
        else:
            answer_text, duration = generate_part3_answer_v2(q_text, overall, fc, lr, gra, pr)
        
        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π answer_id
        max_id = 0
        # –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç—É—é –Ω—É–º–µ—Ä–∞—Ü–∏—é
        answer_id = f'ans_{4022 + i + 1:04d}'
        
        new_answer = {
            'answer_id': answer_id,
            'session_id': random.choice(session_ids),
            'user_id': random.choice(user_ids),
            'part': part,
            'question_id': q_id,
            'question_text': q_text,
            'answer_text': answer_text,
            'duration_sec': str(duration),
            'target_band_overall': str(overall),
            'target_band_fc': str(fc),
            'target_band_lr': str(lr),
            'target_band_gra': str(gra),
            'target_band_pr': str(pr),
            'transcript_raw': answer_text,
            'source_type': 'synthetic_v1.3_low_band',
            'quality_flag': determine_quality_flag(overall)
        }
        
        new_answers.append(new_answer)
    
    return new_answers

def main():
    print("=" * 70)
    print("–°–ë–û–†–ö–ê V1.3: CLEAN & VALIDATED DATASET")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º v1.2
    print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ v1.2...")
    answers = load_answers('dataset_versions/v1.2/answers.csv')
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(answers)} –æ—Ç–≤–µ—Ç–æ–≤")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    print("\nüìã –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
    validation = load_validation_results()
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(validation)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    to_keep = []
    to_regenerate = []
    to_delete = []
    
    for answer in answers:
        answer_id = answer.get('answer_id')
        if answer_id not in validation:
            to_keep.append(answer)
            continue
        
        action = validation[answer_id]['action']
        if action == 'keep':
            to_keep.append(answer)
        elif action == 'regenerate':
            to_regenerate.append(answer)
        elif action == 'delete':
            to_delete.append(answer)
    
    print(f"\nüìä –ö–ê–¢–ï–ì–û–†–ò–ò:")
    print(f"   ‚úÖ Keep: {len(to_keep)}")
    print(f"   üîÑ Regenerate: {len(to_regenerate)}")
    print(f"   üóëÔ∏è  Delete: {len(to_delete)}")
    
    # –†–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º
    print(f"\nüîÑ –†–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è {len(to_regenerate)} –æ—Ç–≤–µ—Ç–æ–≤...")
    regenerated = []
    
    random.seed(42)
    for old_answer in to_regenerate:
        try:
            part = old_answer.get('part', '')
            overall = float(old_answer.get('target_band_overall', 0))
            fc = float(old_answer.get('target_band_fc', 0))
            lr = float(old_answer.get('target_band_lr', 0))
            gra = float(old_answer.get('target_band_gra', 0))
            pr = float(old_answer.get('target_band_pr', 0))
            
            question_text = old_answer.get('question_text', '')
            
            if part == '1':
                answer_text, duration = generate_part1_answer_v2_clean(question_text, overall, fc, lr, gra, pr)
            elif part == '2':
                answer_text, duration = generate_part2_answer_v2_clean(question_text, overall, fc, lr, gra, pr)
            elif part == '3':
                answer_text, duration = generate_part3_answer_v2(question_text, overall, fc, lr, gra, pr)
            else:
                continue
            
            new_answer = old_answer.copy()
            new_answer['answer_text'] = answer_text
            new_answer['transcript_raw'] = answer_text
            new_answer['duration_sec'] = str(duration)
            new_answer['source_type'] = 'synthetic_v1.3'
            new_answer['quality_flag'] = determine_quality_flag(overall)
            
            regenerated.append(new_answer)
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ {old_answer.get('answer_id')}: {e}")
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –æ—Ç–≤–µ—Ç
            to_keep.append(old_answer)
    
    print(f"   ‚úÖ –†–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {len(regenerated)}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º low-band data
    print(f"\n‚ûï –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö low-band –æ—Ç–≤–µ—Ç–æ–≤...")
    low_band_p1 = generate_low_band_data(100, '1')
    low_band_p2 = generate_low_band_data(50, '2')
    low_band_p3 = generate_low_band_data(150, '3')
    print(f"   Part 1: +{len(low_band_p1)}")
    print(f"   Part 2: +{len(low_band_p2)}")
    print(f"   Part 3: +{len(low_band_p3)}")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ
    all_answers = to_keep + regenerated + low_band_p1 + low_band_p2 + low_band_p3
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ answer_id
    try:
        all_answers.sort(key=lambda x: int(x['answer_id'].split('_')[1]))
    except:
        pass
    
    # –°–æ–∑–¥–∞–µ–º v1.3
    output_dir = 'dataset_versions/v1.3'
    os.makedirs(output_dir, exist_ok=True)
    
    # –ö–æ–ø–∏—Ä—É–µ–º users –∏ sessions
    for file in ['users.csv', 'sessions.csv']:
        src = f'dataset_versions/v1.2/{file}'
        dst = f'{output_dir}/{file}'
        if os.path.exists(src):
            shutil.copy2(src, dst)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º answers
    output_file = f'{output_dir}/answers.csv'
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ {output_file}...")
    
    fieldnames = ['answer_id', 'session_id', 'user_id', 'part', 'question_id', 'question_text',
                 'answer_text', 'duration_sec', 'target_band_overall', 'target_band_fc',
                 'target_band_lr', 'target_band_gra', 'target_band_pr', 'transcript_raw',
                 'source_type', 'quality_flag']
    
    # –û—á–∏—â–∞–µ–º –æ—Ç None
    cleaned_answers = []
    for answer in all_answers:
        cleaned = {k: (answer.get(k) or '') for k in fieldnames}
        cleaned_answers.append(cleaned)
    
    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(cleaned_answers)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 70)
    print("‚úÖ –°–¢–ê–¢–ò–°–¢–ò–ö–ê V1.3")
    print("=" * 70)
    print(f"   –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(cleaned_answers)}")
    
    part_counts = defaultdict(int)
    for a in cleaned_answers:
        part_counts[a['part']] += 1
    
    for part in sorted(part_counts.keys()):
        count = part_counts[part]
        pct = count / len(cleaned_answers) * 100
        print(f"   Part {part}: {count} ({pct:.1f}%)")
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –±—ç–Ω–¥–∞–º
    overall_scores = []
    for a in cleaned_answers:
        try:
            overall_scores.append(float(a.get('target_band_overall', 0)))
        except:
            pass
    
    low_mid = sum(1 for s in overall_scores if s <= 6.0)
    high = sum(1 for s in overall_scores if s >= 6.5)
    
    print(f"\n   Low-Mid (‚â§6.0): {low_mid} ({low_mid/len(overall_scores)*100:.1f}%)")
    print(f"   High (‚â•6.5): {high} ({high/len(overall_scores)*100:.1f}%)")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º changelog
    changelog = f"""# V1.3 Changelog

## –ò–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç v1.2

### –£–¥–∞–ª–µ–Ω–æ
- {len(to_delete)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤

### –†–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ
- Part 1: {sum(1 for a in to_regenerate if a.get('part') == '1')} –æ—Ç–≤–µ—Ç–æ–≤
- Part 2: {sum(1 for a in to_regenerate if a.get('part') == '2')} –æ—Ç–≤–µ—Ç–æ–≤
- Part 3: {sum(1 for a in to_regenerate if a.get('part') == '3')} –æ—Ç–≤–µ—Ç–æ–≤

### –î–æ–±–∞–≤–ª–µ–Ω–æ
- Part 1: +{len(low_band_p1)} low-band –æ—Ç–≤–µ—Ç–æ–≤ (4.0-5.0)
- Part 2: +{len(low_band_p2)} low-band –æ—Ç–≤–µ—Ç–æ–≤
- Part 3: +{len(low_band_p3)} low-band –æ—Ç–≤–µ—Ç–æ–≤

### –ò—Ç–æ–≥–æ
- –í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(cleaned_answers)}
- Part 1: {part_counts.get('1', 0)}
- Part 2: {part_counts.get('2', 0)}
- Part 3: {part_counts.get('3', 0)}

## –£–ª—É—á—à–µ–Ω–∏—è

1. –£–±—Ä–∞–Ω—ã –º—É—Å–æ—Ä–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ Part 1 ("genuine appreciation", etc.)
2. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã —à–∞–±–ª–æ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ Part 2 ("time when you", etc.)
3. –û—á–∏—â–µ–Ω—ã –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ —Ñ—Ä–∞–∑—ã Part 3
4. –î–æ–±–∞–≤–ª–µ–Ω—ã low-band –æ—Ç–≤–µ—Ç—ã –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
5. –ü—Ä–æ–≤–µ—Ä–µ–Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤ –≤–æ–ø—Ä–æ—Å–∞–º
"""
    
    with open(f'{output_dir}/CHANGELOG.md', 'w', encoding='utf-8') as f:
        f.write(changelog)
    
    print(f"\nüíæ Changelog —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_dir}/CHANGELOG.md")
    print(f"\n‚úÖ V1.3 —Å–æ–∑–¥–∞–Ω –≤ {output_dir}/")

if __name__ == '__main__':
    main()

